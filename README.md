# zhihu爬虫

该爬虫将会作为毕业设计的数据获取来源，对于知乎这一个平台的数据进行抓取。
爬虫将会尽可能的追求数据的完整性，可持续性和周期性。
希望能够在一定程度上帮助毕业设计上的中文的话题建模等。


## 爬虫1抓取话题结构

之前我单线程抓取，速度太慢，放弃。
改为使用宽度优先配合多进程，进程开销太大，放弃
改为宽度优先配合多线程：
1. 遇见的问题是出现需要上锁的情况，加锁，主要是需要生成一个树状结构，其实知乎话题是图状结构，我简化为第一次出现的树状结构。
2. 在抓取未分类太慢，应该在深度优先的情况时候也使用多线程，post需要连贯的参数，因此还是不靠谱。 
3. 线程太多（100），疯狂429，线程改为5后，情况得到缓解，但是仍然存在，试错1000次机制加入。

宽度优先配合gevent
疯狂429，而且我使用不同的账号用浏览器打开网页也报429

因此我认为启用代理在一定程度上可以改善改情况。

使用代理池项目[python爬虫代理池(proxy pool)](https://github.com/jhao104/proxy_pool)的


[从0到1，Python异步编程的演进之路](https://zhuanlan.zhihu.com/p/25228075)

## 爬虫2获取话题问题列表
zhihuPage，改换了一种config的表示方法

## 爬虫3抓取具体的页面
使用scrapy抓取，不登录抓取问题页面信息。
登录抓取log信息


## 关于登陆信息
使用cookies
![](http://wx4.sinaimg.cn/mw690/006C73MUly1ffaqor57xbj31hc0qd7my.jpg)

